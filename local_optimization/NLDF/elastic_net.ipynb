{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edec5c6-4a7c-41d2-8241-03deed2b6acd",
   "metadata": {},
   "source": [
    "# Using elastic net in a linear regression to predict a possum's length\n",
    "\n",
    "The routine **[handle_solve_nldf](https://support.nag.com/numeric/py/nagdoc_latest/naginterfaces.library.opt.handle_solve_nldf.html)** is a general nonlinear data-fitting solver in the [NAG® Library](https://nag.com/nag-library/) that supports a variety of different loss functions and regularization options - including elastic net.\n",
    "\n",
    "**Elastic net** regularization is a combination of L1 (lasso) and L2 (ridge) regularization that is ideally suited for high-dimensional and noisy data. In these cases, it can be used for **feature selection** by setting the coefficients of irrelevant features to zero. Further, it is particularly useful when dealing with **multicollinear** features - where two or more features are highly correlated. It achieves this by shrinking the coefficients of correlated features towards each other. It also helps to **reduce overfitting** by penalizing large coefficients, which can lead to better generalization performance.\n",
    "\n",
    "To demonstrate the use of elastic net regularization, we will build a linear regression model to predict a possum's total length based upon several features, such as, capture site, age, and head length.\n",
    "\n",
    "Note, the purpose of this notebook is to illustrate the use of handle_solve_nldf which is a general data-fitting framework that utilises nonlinear programming algorithms, such as sequential quadratic programming and interior point method. Therefore, it may not be as performant as one of our dedicated linear regression solvers.\n",
    "\n",
    "\n",
    "**Reference:** \\\n",
    "Lindenmayer, D. B., Viggers, K. L., Cunningham, R. B., and Donnelly, C. F. 1995. Morphological variation among columns of the mountain brushtail possum, Trichosurus caninus Ogilby (Phalangeridae: Marsupiala). Australian Journal of Zoology 43: 449-458. \\\n",
    "Dataset source: https://www.kaggle.com/datasets/abrambeyer/openintro-possum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd8009c-2402-4374-a125-87f7caf0ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from naginterfaces.library import opt\n",
    "from naginterfaces.base import utils\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411c4c6-2c14-40d1-86d0-c5e713f6a0ff",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess the data\n",
    "This dataset has 13 features and 101 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5497ff22-6a92-4cd5-a112-ed4a3250435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>Pop</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>hdlngth</th>\n",
       "      <th>skullw</th>\n",
       "      <th>totlngth</th>\n",
       "      <th>taill</th>\n",
       "      <th>footlgth</th>\n",
       "      <th>earconch</th>\n",
       "      <th>eye</th>\n",
       "      <th>chest</th>\n",
       "      <th>belly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>m</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94.1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>54.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>57.6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>51.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>51.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>6.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>57.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>52.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Vic</td>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>56.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>53.2</td>\n",
       "      <td>15.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site  Pop sex  age  hdlngth  skullw  totlngth  taill  footlgth  earconch  \\\n",
       "0     1  Vic   m  8.0     94.1    60.4      89.0   36.0      74.5      54.5   \n",
       "1     1  Vic   f  6.0     92.5    57.6      91.5   36.5      72.5      51.2   \n",
       "2     1  Vic   f  6.0     94.0    60.0      95.5   39.0      75.4      51.9   \n",
       "3     1  Vic   f  6.0     93.2    57.1      92.0   38.0      76.1      52.2   \n",
       "4     1  Vic   f  2.0     91.5    56.3      85.5   36.0      71.0      53.2   \n",
       "\n",
       "    eye  chest  belly  \n",
       "0  15.2   28.0   36.0  \n",
       "1  16.0   28.5   33.0  \n",
       "2  15.5   30.0   34.0  \n",
       "3  15.2   28.0   34.0  \n",
       "4  15.1   28.5   33.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('possum.csv', usecols=range(1,14))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06841ec7-443e-4831-b013-3aa79cc5333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NAN data\n",
    "df.dropna(axis=0,inplace=True)\n",
    "\n",
    "# Categorical features (site, population, sex) need to be one-hot encoded\n",
    "df_encoded = pd.get_dummies(df, columns=['site','Pop','sex'], dtype=float, drop_first=True)\n",
    "\n",
    "# Extract total length (y), which is the variable to be predicted\n",
    "y = df_encoded[[\"totlngth\"]].values\n",
    "X = df_encoded.drop(columns=[\"totlngth\"]).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654fd99-5544-42d4-8467-b959b109f3cd",
   "metadata": {},
   "source": [
    "## 2. Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6e103d-4e2c-4640-b8d5-9f690c444192",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_test(X, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy array): Features\n",
    "    y (numpy array): Observations\n",
    "    test_size (float, optional): Proportion of data to use for testing\n",
    "\n",
    "    Returns:\n",
    "    X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    # Get total number of samples\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # Calculate number of test samples\n",
    "    num_test_samples = int(num_samples * test_size)\n",
    "\n",
    "    # Generate random indices for training set\n",
    "    train_indices = np.random.choice(num_samples, num_samples - num_test_samples, replace=False)\n",
    "\n",
    "    # Create training sets\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "\n",
    "    # Create testing sets\n",
    "    test_indices = np.setdiff1d(np.arange(num_samples), train_indices)\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86657422-9e33-45ff-899f-7f7840150914",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Scale the training and testing datasets.\n",
    "\n",
    "    Returns:\n",
    "    X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    mu = X_train.mean(0)\n",
    "    sigma = X_train.std(0)\n",
    "    for j in range(X_train.shape[-1]):\n",
    "        xs = X_train[:,j]\n",
    "        is_categorical = np.logical_or(np.isclose(xs, 1.), np.isclose(xs, 0.)).all()\n",
    "        if not is_categorical:\n",
    "            X_train[:,j] = (X_train[:,j] - mu[j]) / sigma[j]\n",
    "            X_test[:,j] = (X_test[:,j] - mu[j]) / sigma[j]\n",
    "    \n",
    "    y_test = (y_test - y_train.mean()) / y_train.std()\n",
    "    y_train = (y_train - y_train.mean()) / y_train.std()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487c2e0f-f494-4ac3-8c34-1db320178693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes: (81, 17) (81, 1)\n",
      "Testing set shapes: (20, 17) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, y_train, X_test, y_test = train_test(X, y)\n",
    "\n",
    "# Scale the data\n",
    "X_train, y_train, X_test, y_test = scale_data(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"Training set shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shapes:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd46ae-881f-4d5d-b174-0ee5a66703b7",
   "metadata": {},
   "source": [
    "## 3. Fit a linear regression with least squares loss and elastic net regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4796a5-724c-4a55-b485-4b18ce603328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E04GN, Nonlinear Data-Fitting\n",
      " Status: converged, an optimal solution found\n",
      " Final objective value  1.652821E+01\n"
     ]
    }
   ],
   "source": [
    "# Number of variables = number of features + bias term\n",
    "nvar = X_train.shape[1] + 1\n",
    "\n",
    "# Create a handle for the model\n",
    "handle = opt.handle_init(nvar=nvar)\n",
    "\n",
    "# Register residual structure\n",
    "nres =  X_train.shape[0]\n",
    "opt.handle_set_nlnls(handle, nres)\n",
    "\n",
    "# Create the data structure to be passed to the solver\n",
    "data = {}\n",
    "data[\"X_train\"] = X_train\n",
    "data[\"y_train\"] = y_train\n",
    "\n",
    "# Define the residual callback function and its gradient\n",
    "def lsqfun(x, nres, inform, data):\n",
    "    rx = np.zeros(nres, dtype=float)\n",
    "    X_train = data[\"X_train\"]\n",
    "    y_train = data[\"y_train\"].squeeze()\n",
    "    \n",
    "    # Fit a linear regression to the data\n",
    "    r_full = y_train - (x[0] + X_train @ x[1:]) \n",
    "    for i in range(nres):\n",
    "        rx[i] = r_full[i]\n",
    " \n",
    "    return rx, inform\n",
    "    \n",
    "def lsqgrd(x, nres, rdx, inform, data):\n",
    "    X_train = data[\"X_train\"]\n",
    "\n",
    "    for i in range(nres):\n",
    "        for j in range(nvar):\n",
    "            if j==0:\n",
    "                rdx[i*nvar] = -1               \n",
    "            else:\n",
    "                rdx[i*nvar + j] = -X_train[i, j-1]\n",
    "            \n",
    "    return inform\n",
    "\n",
    "# Set loss function to l2-norm, elastic net regularization, and printing options\n",
    "for option in [\n",
    "    'NLDF Loss Function Type = L2',\n",
    "    'Print Level = 1',\n",
    "    'Print Options = No',\n",
    "    'Reg Term Type = Elastic Net',\n",
    "    ]:\n",
    "    opt.handle_opt_set (handle, option)\n",
    "\n",
    "# Use an explicit I/O manager for abbreviated iteration output\n",
    "iom = utils.FileObjManager(locus_in_output=False)\n",
    "\n",
    "# Set initial guess and solve\n",
    "x = np.array([np.random.rand() for _ in range(nvar)])\n",
    "\n",
    "sol_en = opt.handle_solve_nldf(handle, lsqfun, lsqgrd, x, nres, data=data, io_manager=iom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b84636fe-1a3c-4188-8dec-7449dbc059b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " E04GN, Nonlinear Data-Fitting\n",
      " Status: converged, an optimal solution found\n",
      " Final objective value  1.362383E+01\n"
     ]
    }
   ],
   "source": [
    "# Resolve the problem with no regularization\n",
    "opt.handle_opt_set(handle, 'Reg Term Type = Off')\n",
    "sol_noreg = opt.handle_solve_nldf(handle, lsqfun, lsqgrd, x, nres, data=data, io_manager=iom)\n",
    "\n",
    "# Destroy the handle\n",
    "opt.handle_free(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada90e01-6845-41b8-9f91-9944497a94ed",
   "metadata": {},
   "source": [
    "## 4. Compute root mean square error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "126cca3a-2b1e-461b-af09-df70c8c636b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_rmse(y_actual, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Square Error (RMSE) between two lists of numbers\n",
    "\n",
    "    Args:\n",
    "        y_actual (list): The actual values\n",
    "        y_pred (list): The predicted values\n",
    "\n",
    "    Returns:\n",
    "        float: The Root Mean Squared Error\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.square(y_actual - y_pred).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207f4ff1-b1c3-4c54-81ff-4789fa3bbad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using elastic net regularization decreased the RMSE by 0.034 compared to using no regularization.\n"
     ]
    }
   ],
   "source": [
    "# Calculate predicted values for y with elastic net regularization and find RMSE\n",
    "y_pred_en = sol_en.x[0] + X_test @ sol_en.x[1:]\n",
    "rmse_elastic_net = calculate_rmse(y_test, y_pred_en)\n",
    "\n",
    "# Calculate predicted values for y with no regularization and find RMSE\n",
    "y_pred_noreg = sol_noreg.x[0] + X_test @ sol_noreg.x[1:]\n",
    "rmse_noreg = calculate_rmse(y_test, y_pred_noreg)\n",
    "\n",
    "# Report the difference in RMSE\n",
    "print(f\"Using elastic net regularization decreased the RMSE by {round(rmse_noreg - rmse_elastic_net, 4)} compared to using no regularization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfdf65a-c992-4c48-ba6a-0a8438328218",
   "metadata": {},
   "source": [
    "For more information on the NAG® Library and our [Optimization Modelling Suite](https://nag.com/mathematical-optimization/) or to try it for yourself, visit [‘Getting Started with the NAG Library’](https://support.nag.com/content/getting-started-nag-library?_gl=1*xmlppm*_gcl_au*MTEwNDczODM2NS4xNzIyMDAyNzkz*_ga*MjA2NzgxMjY0NS4xNzIyMDAyNzk0*_ga_6MCQDQP46G*MTcyMzEzNDUxNi41LjAuMTcyMzEzNDUzNy4zOS4wLjA.), select your configuration and language, download the software, request a trial key and experiment for yourself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
