{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naginterfaces.library import opt\n",
    "import numpy as np\n",
    "from naginterfaces.base import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix completion using Semi-Definite Programming (SDP)\n",
    "\n",
    "## Correct Rendering of this notebook\n",
    "\n",
    "This notebook makes use of the `latex_envs` Jupyter extension for equations and references.  If the LaTeX is not rendering properly in your local installation of Jupyter , it may be because you have not installed this extension.  Details at https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/latex_envs/README.html\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a survey of $n_r$ respondent with $n_q$ questions. Unfortunately, some of the entries are missing...\n",
    "\n",
    "Here is an example with $n_r = 15$ and $n_q = 6$\n",
    "\\begin{equation*}\n",
    "\\hat{Y} = \n",
    "\\begin{bmatrix}\n",
    "* & * & * & * & * &  0.4\\\\\n",
    "0.6 &  0.4 &  0.8 & * & * & *\\\\\n",
    "1.0 & * &  0.8 & * &  0.2 & *\\\\\n",
    "0.8 &  0.2 & * & * & * & *\\\\\n",
    "1.0 &  0.4 & * &  0.0 & * &  0.2\\\\\n",
    "0.4 & * & * &  0.2 & * &  0.2\\\\\n",
    "1.0 &  0.8 &  0.2 &  0.6 & * & *\\\\\n",
    "1.0 & * &  0.2 & * & * & *\\\\\n",
    "1.0 &  0.4 & * &  0.6 &  0.0 & *\\\\\n",
    "1.0 & * &  0.4 & * & * & *\\\\\n",
    "1.0 & * &  0.2 &  0.2 &  0.4 &  0.4\\\\\n",
    "1.0 & * & * & * &  1.0 &  0.8\\\\\n",
    "1.0 & * &  0.2 & * & * &  0.6\\\\\n",
    "1.0 & * & * & * & * &  0.2\\\\\n",
    "0.6 & * &  0.2 &  0.4 & * & *\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "What is the best way to fill the missing values? One way to look at it would be to say that respondents with similar answers should stay similar. In practice, this can be modelled as minimizing the rank of $Y$.\n",
    "\\begin{equation*}\n",
    "\\min_Y rank(Y)\\\\\n",
    "Y_{ij} = \\hat{Y}_{ij}\n",
    "\\end{equation*}\n",
    "Rank minimization is in general NP-hard but it can be approximated by a heuristic, minimizing the nuclear norm of the matrix. The nuclear norm of a matrix is the sum of its singular values. A rank deficient matrix must have (several) zero singular values. Given the fact that the singular values are always non-negative, a minimization of the nuclear norm has the same effect as $l_1$ norm in compress sensing, i.e., it encourages many singular values to be zero and thus it can be considered as a heuristic for the original rank minimization problem.\n",
    "\\begin{equation*}\n",
    "\\min_Y ||Y||_*\\\\\n",
    "Y_{ij} = \\hat{Y}_{ij}\n",
    "\\end{equation*}\n",
    "This can be achieved by solving the following SDP problem:\n",
    "\\begin{equation*}\n",
    "\\min_{Y, W_1, W_2} trace(W_1) + trace(W_2)\\\\\n",
    "Y_{ij} = \\hat{Y}_{ij}\\\\\n",
    "\\begin{bmatrix}\n",
    "W_1 & Y\\\\\n",
    "Y^T & W_2\n",
    "\\end{bmatrix} \\succeq 0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by defining the data\n",
    "nr = 15\n",
    "nq = 6\n",
    "# Matrix, missing values set to-1\n",
    "Y = np.array([[-1.0,-1.0,-1.0,-1.0,-1.0, 0.4],\n",
    "                [ 0.6, 0.4, 0.8,-1.0,-1.0,-1.0],\n",
    "                [-1.0,-1.0, 0.8,-1.0, 0.2,-1.0],\n",
    "                [ 0.8, 0.2,-1.0,-1.0,-1.0,-1.0],\n",
    "                [-1.0, 0.4,-1.0, 0.0,-1.0, 0.2],\n",
    "                [ 0.4,-1.0,-1.0, 0.2,-1.0, 0.2],\n",
    "                [-1.0, 0.8, 0.2, 0.6,-1.0,-1.0],\n",
    "                [-1.0,-1.0, 0.2,-1.0,-1.0,-1.0],\n",
    "                [-1.0, 0.4,-1.0, 0.6, 0.0,-1.0],\n",
    "                [-1.0,-1.0, 0.4,-1.0,-1.0,-1.0],\n",
    "                [-1.0,-1.0, 0.2, 0.2, 0.4, 0.4],\n",
    "                [-1.0,-1.0,-1.0,-1.0, 1.0, 0.8],\n",
    "                [ 1.0,-1.0, 0.2,-1.0,-1.0, 0.6],\n",
    "                [-1.0,-1.0,-1.0,-1.0,-1.0, 0.2],\n",
    "                [ 0.6,-1.0, 0.2, 0.4,-1.0,-1.0]])\n",
    "\n",
    "# Count the number of missing element\n",
    "n_miss = 0\n",
    "for i in range(nr):\n",
    "    for j in range(nq):\n",
    "        if Y[i][j] <= -1.0:\n",
    "            n_miss += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start defining the SDP problem. $W_1$ and $W_2$ are full matrices of variables, respectively $n_r \\times n_r$ and $n_q \\times n_q$. Additionally, the missing values are also be variables of the optimization problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of variables: missing values + 2 full matrix nrxnr and nqxnq \n",
    "# (only the upper triangular part is needed)\n",
    "nvar = int(n_miss + nr*(nr+1)/2 + nq*(nq+1)/2)\n",
    "\n",
    "# Initialize the problem handle\n",
    "handle = opt.handle_init(nvar)\n",
    "\n",
    "# Initialize the linear objective to 0.0\n",
    "cvec = np.zeros(nvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start defining the linear matrix inequality. First the known values of $\\hat{Y}$, stored in the constant part of the matrix inequality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sparse matrix inequality matrices \n",
    "nnzasum = nvar + nr*nq - n_miss\n",
    "nnza = np.empty(nvar+1, dtype=int)\n",
    "irowa = np.empty(nnzasum, dtype=int)\n",
    "icola = np.empty(nnzasum, dtype=int)\n",
    "a = np.empty(nnzasum, dtype=float)\n",
    "\n",
    "# number of nonzeros in the constant block\n",
    "nnza[0] = nr*nq - n_miss\n",
    "\n",
    "# All the other matrices in the combination only have one element\n",
    "nnza[1:] = 1\n",
    "\n",
    "# Fill A_0 with the known values of Y\n",
    "idx = 0\n",
    "for i in range(nr):\n",
    "    for j in range(nq):\n",
    "        if Y[i][j] >= 0.0:\n",
    "            irowa[idx] = i + 1\n",
    "            icola[idx] = nr + j + 1\n",
    "            a[idx] = -Y[i][j]\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fill the upper left block\n",
    "\\begin{bmatrix}\n",
    "W_1 & * \\\\\n",
    "* & *\n",
    "\\end{bmatrix}\n",
    "consisting of the upper triangular part of $W_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1x1 block of the matrix\n",
    "# Fill the objective vector at the same time\n",
    "idxobj = 0\n",
    "for i in range(nr):\n",
    "    # this is a diagonal element of W1, it belongs to the trace (set objective)\n",
    "    cvec[idxobj] = 1.0\n",
    "    for j in range(i, nr):\n",
    "        irowa[idx] = i + 1\n",
    "        icola[idx] = j + 1\n",
    "        a[idx] = 1.0\n",
    "        idx += 1\n",
    "        idxobj += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for the lower right block\n",
    "\\begin{bmatrix}\n",
    "* & * \\\\\n",
    "* & W_2\n",
    "\\end{bmatrix}\n",
    "consisting of the upper triangular part of $W_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nq):\n",
    "    # this is a diagonal element of W2, it belongs to the trace (set objective)\n",
    "    cvec[idxobj] = 1.0\n",
    "    for j in range(i, nq):\n",
    "        irowa[idx] = nr + i + 1\n",
    "        icola[idx] = nr + j + 1\n",
    "        a[idx] = 1.0\n",
    "        idx += 1\n",
    "        idxobj += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the missing elements of $Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nr):\n",
    "    for j in range(nq):\n",
    "        if Y[i][j] < 0.0:\n",
    "            irowa[idx] = i + 1 \n",
    "            icola[idx] = nr + j + 1\n",
    "            a[idx] = 1.0\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the problem handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the linear objective to the handle\n",
    "opt.handle_set_linobj(handle, cvec)\n",
    "\n",
    "# Add the linear matrix inequalities\n",
    "dima = nr + nq\n",
    "idblk = opt.handle_set_linmatineq(handle, dima, nnza, irowa, icola, a, blksizea=None, idblk=0)\n",
    "\n",
    "# Set optional argument\n",
    "for option in ['Print Options = No',\n",
    "               'Initial X = Automatic',\n",
    "               'Dimacs = Check']:\n",
    "    opt.handle_opt_set(handle, option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is ready to be solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --------------------------------\n",
      "  E04SV, NLP-SDP Solver (Pennon)\n",
      " --------------------------------\n",
      "\n",
      " Problem Statistics\n",
      "   No of variables                196\n",
      "     bounds               not defined\n",
      "   No of lin. constraints           0\n",
      "     nonzeroes                      0\n",
      "   No of matrix inequal.            1\n",
      "     detected matrix inq.           1\n",
      "       linear                       1\n",
      "       nonlinear                    0\n",
      "       max. dimension              21\n",
      "     detected normal inq.           0\n",
      "       linear                       0\n",
      "       nonlinear                    0\n",
      "   Objective function          Linear\n",
      "\n",
      " --------------------------------------------------------------\n",
      "  it|  objective |  optim  |   feas  |  compl  | pen min |inner\n",
      " --------------------------------------------------------------\n",
      "   0  0.00000E+00  9.17E+01  1.91E+00  0.00E+00  2.00E+00   0\n",
      "   1  1.53207E+02  6.26E-03  0.00E+00  1.50E+02  2.00E+00  13\n",
      "   2  7.10956E+01  1.75E-02  0.00E+00  6.45E+01  9.04E-01   4\n",
      "   3  3.68500E+01  1.36E-02  0.00E+00  2.73E+01  4.08E-01   5\n",
      "   4  2.25150E+01  1.07E-02  0.00E+00  1.15E+01  1.85E-01   4\n",
      "   5  1.64698E+01  1.10E-02  0.00E+00  4.84E+00  8.34E-02   5\n",
      "   6  1.38820E+01  4.07E-03  0.00E+00  2.06E+00  3.77E-02   5\n",
      "   7  1.27611E+01  7.27E-03  0.00E+00  8.83E-01  1.70E-02   5\n",
      "   8  1.22745E+01  4.16E-03  0.00E+00  3.82E-01  7.70E-03   4\n",
      "   9  1.20628E+01  3.53E-03  0.00E+00  1.65E-01  3.48E-03   4\n",
      "  10  1.19705E+01  3.14E-03  0.00E+00  7.20E-02  1.57E-03   4\n",
      "  11  1.19303E+01  3.67E-03  0.00E+00  3.13E-02  7.11E-04   4\n",
      "  12  1.19127E+01  3.65E-03  0.00E+00  1.37E-02  3.21E-04   4\n",
      "  13  1.19050E+01  4.02E-03  0.00E+00  5.96E-03  1.45E-04   4\n",
      "  14  1.19017E+01  1.35E-04  0.00E+00  2.60E-03  6.56E-05   5\n",
      " --------------------------------------------------------------\n",
      "  it|  objective |  optim  |   feas  |  compl  | pen min |inner\n",
      " --------------------------------------------------------------\n",
      "  15  1.19002E+01  9.38E-07  0.00E+00  1.13E-03  2.96E-05   5\n",
      "  16  1.18996E+01  1.51E-06  0.00E+00  4.90E-04  1.34E-05   5\n",
      "  17  1.18993E+01  1.45E-10  0.00E+00  2.12E-04  6.06E-06   6\n",
      "  18  1.18992E+01  3.23E-10  0.00E+00  9.14E-05  2.74E-06   6\n",
      "  19  1.18991E+01  1.09E-09  0.00E+00  3.93E-05  1.24E-06   6\n",
      "  20  1.18991E+01  1.70E-09  0.00E+00  1.68E-05  5.59E-07   6\n",
      "  21  1.18991E+01  6.16E-09  0.00E+00  7.15E-06  2.53E-07   6\n",
      "  22  1.18991E+01  1.55E-08  0.00E+00  3.02E-06  1.14E-07   6\n",
      "  23  1.18991E+01  2.19E-08  0.00E+00  1.27E-06  5.16E-08   6\n",
      " --------------------------------------------------------------\n",
      " Status: converged, an optimal solution found\n",
      " --------------------------------------------------------------\n",
      " Final objective value                1.189910E+01\n",
      " Relative precision                   1.359557E-07\n",
      " Optimality                           2.187594E-08\n",
      " Feasibility                          0.000000E+00\n",
      " Complementarity                      1.267053E-06\n",
      " DIMACS error 1                       1.093797E-08\n",
      " DIMACS error 2                       0.000000E+00\n",
      " DIMACS error 3                       0.000000E+00\n",
      " DIMACS error 4                       0.000000E+00\n",
      " DIMACS error 5                       5.004717E-08\n",
      " DIMACS error 6                       5.109456E-08\n",
      " Iteration counts\n",
      "   Outer iterations                             23\n",
      "   Inner iterations                            122\n",
      "   Linesearch steps                            332\n",
      " Evaluation counts\n",
      "   Augm. Lagr. values                          146\n",
      "   Augm. Lagr. gradient                        146\n",
      "   Augm. Lagr. hessian                         122\n",
      " --------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# I/O\n",
    "iom = utils.FileObjManager(locus_in_output=False)\n",
    "\n",
    "# Call the solver\n",
    "x = np.empty(nvar)\n",
    "inform = 0\n",
    "x, _, _, _, rinfo, stats, _ = opt.handle_solve_pennon(handle, x, inform, u=None, \n",
    "                                                      uc=None, ua=None, io_manager=iom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the completed matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.3 0.2 0.2 0.4 0.4]\n",
      " [0.6 0.4 0.8 0.2 0.3 0.4]\n",
      " [0.4 0.3 0.8 0.  0.2 0.2]\n",
      " [0.8 0.2 0.3 0.4 0.3 0.4]\n",
      " [0.  0.4 0.2 0.  0.2 0.2]\n",
      " [0.4 0.1 0.2 0.2 0.1 0.2]\n",
      " [0.6 0.8 0.2 0.6 0.2 0.4]\n",
      " [0.1 0.1 0.2 0.  0.  0.1]\n",
      " [0.6 0.4 0.1 0.6 0.  0.3]\n",
      " [0.2 0.1 0.4 0.  0.1 0.1]\n",
      " [0.5 0.3 0.2 0.2 0.4 0.4]\n",
      " [0.7 0.4 0.3 0.  1.  0.8]\n",
      " [1.  0.3 0.2 0.5 0.5 0.6]\n",
      " [0.2 0.1 0.1 0.1 0.2 0.2]\n",
      " [0.6 0.3 0.2 0.4 0.2 0.3]]\n",
      "The rank of the filled matrix is: 4\n"
     ]
    }
   ],
   "source": [
    "# Fill the missing elements of the matrix\n",
    "idx = int(nr*(nr+1)/2 + nq*(nq+1)/2)\n",
    "for i in range(nr):\n",
    "    for j in range(nq):\n",
    "        if Y[i][j] < 0.0:\n",
    "            Y[i][j] = x[idx]\n",
    "            idx += 1\n",
    "            \n",
    "np.set_printoptions(precision=1)\n",
    "print(Y)\n",
    "\n",
    "rk = np.linalg.matrix_rank(Y, tol=1.0e-05)\n",
    "print('The rank of the filled matrix is:', rk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function handle_solve_pennon in module naginterfaces.library.opt:\n",
      "\n",
      "handle_solve_pennon(handle, x, inform, u=None, uc=None, ua=None, io_manager=None)\n",
      "    Run the Pennon solver on a compatible problem initialized by\n",
      "    ``handle_init`` and defined by other functions from the suite, such\n",
      "    as, semidefinite programming (SDP) and SDP with bilinear matrix\n",
      "    inequalities (BMI).\n",
      "    \n",
      "    Note: this function uses optional algorithmic parameters, see also:\n",
      "    ``handle_opt_set``, ``handle_opt_get``.\n",
      "    \n",
      "    ``handle_solve_pennon`` is a solver from the NAG optimization\n",
      "    modelling suite for problems such as, Quadratic Programming (QP),\n",
      "    linear Semidefinite Programming (SDP) and semidefinite programming\n",
      "    with bilinear matrix inequalities (BMI-SDP).\n",
      "    \n",
      "    For full information please refer to the NAG Library document for\n",
      "    e04sv\n",
      "    \n",
      "    https://www.nag.com/numeric/nl/nagdoc_27.1/flhtml/e04/e04svf.html\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    handle : Handle\n",
      "        The handle to the problem. It needs to be initialized (e.g., by\n",
      "        ``handle_init``) and to hold a problem formulation compatible\n",
      "        with ``handle_solve_pennon``. It **must not** be changed between\n",
      "        calls to the NAG optimization modelling suite.\n",
      "    \n",
      "    x : float, array-like, shape (nvar)\n",
      "        Note: intermediate stops take place only if 'Monitor Frequency'\n",
      "        > 0.\n",
      "    \n",
      "        If 'Initial X' = 'USER' (the default), x^0, the initial estimate\n",
      "        of the variables x; otherwise, `x` need not be set.\n",
      "    \n",
      "        `On intermediate entry`: the input is ignored.\n",
      "    \n",
      "    inform : int\n",
      "        Note: intermediate stops take place only if 'Monitor Frequency'\n",
      "        > 0.\n",
      "    \n",
      "        `On initial entry`: no effect.\n",
      "    \n",
      "        `On intermediate entry`: if set to 0, solving the current\n",
      "        problem is terminated and the function returns `errno` = 20;\n",
      "        otherwise, the function continues.\n",
      "    \n",
      "    u : None or float, array-like, shape (nnzu), optional\n",
      "        Note: intermediate stops take place only if 'Monitor Frequency'\n",
      "        > 0.\n",
      "    \n",
      "        Note: if nnzu > 0, `u` holds Lagrangian multipliers (dual\n",
      "        variables) for (standard) constraints, i.e., simple bounds\n",
      "        defined by ``handle_set_simplebounds`` and a set of m_B linear\n",
      "        constraints defined by ``handle_set_linconstr``. Either their\n",
      "        initial estimates, intermediate approximations or final values,\n",
      "        see [Structure of the Lagrangian Multipliers].\n",
      "    \n",
      "        Note: if nnzu = 0, `u` will not be referenced.\n",
      "    \n",
      "        If 'Initial U' = 'USER' (the default is 'AUTOMATIC'), u^0, the\n",
      "        initial estimate of the Lagrangian multipliers u; otherwise, `u`\n",
      "        need not be set.\n",
      "    \n",
      "        `On intermediate entry`: the input is ignored.\n",
      "    \n",
      "    uc : None or float, array-like, shape (nnzuc), optional\n",
      "        `uc` is reserved for future releases of the NAG Library which\n",
      "        will allow definition of second-order cone constraints.\n",
      "    \n",
      "        It is not referenced at the moment.\n",
      "    \n",
      "    ua : None or float, array-like, shape (nnzua), optional\n",
      "        Note: intermediate stops take place only if 'Monitor Frequency'\n",
      "        > 0.\n",
      "    \n",
      "        If nnzua > 0, `ua` holds the Lagrangian multipliers for matrix\n",
      "        constraints defined by ``handle_set_linmatineq`` and\n",
      "        ``handle_set_quadmatineq``, see [Structure of the Lagrangian\n",
      "        Multipliers].\n",
      "    \n",
      "        If nnzua = 0, `ua` will not be referenced.\n",
      "    \n",
      "        If 'Initial U' = 'USER' (the default is 'AUTOMATIC'), U^0, the\n",
      "        initial estimate of the matrix Lagrangian multipliers U;\n",
      "        otherwise, `ua` need not be set.\n",
      "    \n",
      "        `On intermediate entry`: the input is ignored.\n",
      "    \n",
      "    io_manager : FileObjManager, optional\n",
      "        Manager for I/O in this routine.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    x : float, ndarray, shape (nvar)\n",
      "        `On intermediate exit`: the value of the variables x at the end\n",
      "        of the current outer iteration.\n",
      "    \n",
      "        `On final exit`: the final value of the variables x.\n",
      "    \n",
      "    u : float, ndarray, shape (nnzu)\n",
      "        `On intermediate exit`: the estimate of the multipliers u at the\n",
      "        end of the current outer iteration.The final value of\n",
      "        multipliers u.\n",
      "    \n",
      "    uc : float, ndarray, shape (nnzuc)\n",
      "        `uc` is reserved for future releases of the NAG Library which\n",
      "        will allow definition of second-order cone constraints.\n",
      "    \n",
      "        It is not referenced at the moment.\n",
      "    \n",
      "    ua : float, ndarray, shape (nnzua)\n",
      "        `On intermediate exit`: the estimate of the matrix multipliers U\n",
      "        at the end of the outer iteration.\n",
      "    \n",
      "        `On final exit`: the final estimate of the multipliers U.\n",
      "    \n",
      "    rinfo : float, ndarray, shape (32)\n",
      "        `On intermediate or final entry`: error measures and various\n",
      "        indicators (see [Algorithmic Details] for details) at the end of\n",
      "        the current (or final) outer iteration as given in the table\n",
      "        below:\n",
      "    \n",
      "        [table omitted]\n",
      "    \n",
      "    stats : float, ndarray, shape (32)\n",
      "        `On intermediate or final exit`: solver statistics at the end of\n",
      "        the current (or final) outer iteration as given in the table\n",
      "        below. Note that time statistics is provided only if 'Stats\n",
      "        Time' is set (the default is 'NO'), the measured time is\n",
      "        returned in seconds.\n",
      "    \n",
      "        [table omitted]\n",
      "    \n",
      "    inform : int\n",
      "        Note: intermediate stops take place only if 'Monitor Frequency'\n",
      "        > 0.\n",
      "    \n",
      "        `On intermediate exit`: `inform` = 1.\n",
      "    \n",
      "        `On final exit`: `inform` = 0.\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    'Defaults' : valueless\n",
      "        This special keyword may be used to reset all options to their\n",
      "        default values.\n",
      "        Any value given with this keyword will be ignored.\n",
      "    \n",
      "    'DIMACS Measures' : str\n",
      "        Default = 'CHECK'\n",
      "    \n",
      "        If the problem is a linear semidefinite programming problem,\n",
      "        this argument specifies if DIMACS error measures (see [Stopping\n",
      "        Criteria]) should be computed and/or checked.\n",
      "        In other cases, this option reverts to 'NO' automatically.\n",
      "    \n",
      "        Constraint: 'DIMACS Measures' = 'COMPUTE', 'CHECK' or 'NO'.\n",
      "    \n",
      "    'Hessian Density' : str\n",
      "        Default = 'AUTO'\n",
      "    \n",
      "        This option guides the solver on how the Hessian matrix of\n",
      "        augmented Lagrangian F(x,u,v,U,p,P) should be built.\n",
      "        Option 'AUTO' leaves the decision to the solver and it is the\n",
      "        recommended option.\n",
      "        Setting it to 'DENSE' bypasses the autodetection and the Hessian\n",
      "        is always built as a dense matrix.\n",
      "        Option 'SPARSE' instructs the solver to use a sparse storage and\n",
      "        factorization of the matrix if possible.\n",
      "    \n",
      "        Constraint: 'Hessian Density' = 'AUTO', 'DENSE' or 'SPARSE'\n",
      "    \n",
      "    'Infinite Bound Size' : float\n",
      "        Default = 10^20\n",
      "    \n",
      "        This defines the 'infinite' bound bigbnd in the definition of\n",
      "        the problem constraints.\n",
      "        Any upper bound greater than or equal to bigbnd will be regarded\n",
      "        as + infinity (and similarly any lower bound less than or equal\n",
      "        to -bigbnd will be regarded as - infinity).\n",
      "        Note that a modification of this option does not influence\n",
      "        constraints which have already been defined; only the\n",
      "        constraints formulated after the change will be affected.\n",
      "    \n",
      "        Constraint: 'Infinite Bound Size' >= 1000.\n",
      "    \n",
      "    'Initial P' : str\n",
      "        Default = 'AUTOMATIC'\n",
      "    \n",
      "        This option defines the choice of the penalty options p^0, P^0,\n",
      "        see [Algorithm 1].\n",
      "    \n",
      "        'Initial P' = 'AUTOMATIC'\n",
      "            The penalty options are chosen automatically as set by\n",
      "            option 'Init Value P', 'Init Value Pmat' and subject to\n",
      "            automatic scaling. Note that P^0 might be increased so that\n",
      "            the penalty function Phi_P() is defined for all matrix\n",
      "            constraints at the starting point.\n",
      "    \n",
      "        'Initial P' = 'KEEP PREVIOUS'\n",
      "            The penalty options are kept from the previous run of the\n",
      "            solver if possible. If not, this options reverts to\n",
      "            'AUTOMATIC'. Note that even if the matrix penalty options\n",
      "            are the same as in the previous run, they are still subject\n",
      "            to a possible increase so that the penalty function Phi_P()\n",
      "            is well defined at the starting point.\n",
      "    \n",
      "        Constraint: 'Initial P' = 'AUTOMATIC' or 'KEEP PREVIOUS'.\n",
      "    \n",
      "    'Initial U' : str\n",
      "        Default = 'AUTOMATIC'\n",
      "    \n",
      "        This argument guides the solver on which initial Lagrangian\n",
      "        multipliers are to be used.\n",
      "    \n",
      "        'Initial U' = 'AUTOMATIC'\n",
      "            The Lagrangian multipliers are chosen automatically as set\n",
      "            by automatic scaling.\n",
      "    \n",
      "        'Initial U' = 'USER'\n",
      "            The values of arrays `u` and `ua` (if provided) are used as\n",
      "            the initial Lagrangian multipliers subject to automatic\n",
      "            adjustments. If one or the other array is not provided, the\n",
      "            choice for missing data is as in 'AUTOMATIC'.\n",
      "    \n",
      "        'Initial U' = 'KEEP PREVIOUS'\n",
      "            The Lagrangian multipliers are kept from the previous run of\n",
      "            the solver. If this option is set for the first run or\n",
      "            options change the approach of the solver, the choice\n",
      "            automatically reverts to 'AUTOMATIC'. This might be useful\n",
      "            if the solver is hot started, for example, to achieve higher\n",
      "            precision of the solution.\n",
      "    \n",
      "        Constraint: 'Initial U' = 'AUTOMATIC', 'USER' or 'KEEP\n",
      "        PREVIOUS'.\n",
      "    \n",
      "    'Initial X' : str\n",
      "        Default = 'USER'\n",
      "    \n",
      "        This argument guides which starting point x^0 is to be used.\n",
      "    \n",
      "        'Initial X' = 'AUTOMATIC'\n",
      "            The starting point is chosen automatically so that it\n",
      "            satisfies simple bounds on the variables or as a zero\n",
      "            vector. Input of argument `x` is ignored.\n",
      "    \n",
      "        'Initial X' = 'USER'\n",
      "            Initial values of argument `x` are used as a starting point.\n",
      "    \n",
      "        Constraint: 'Initial X' = 'AUTOMATIC' or 'USER'.\n",
      "    \n",
      "    'Init Value P' : float\n",
      "        Default = 1.0\n",
      "    \n",
      "        This argument defines the value p^0, the initial penalty option\n",
      "        for (standard) inequalities.\n",
      "        A low value of the penalty causes the solution of the inner\n",
      "        problem to be closer to the feasible region and thus to the\n",
      "        desirable result.\n",
      "        However, it also increases ill-conditioning of the system.\n",
      "        It is not advisable to set the penalty too low unless a good\n",
      "        starting point is provided.\n",
      "    \n",
      "        Constraint: fourthroot(epsilon) <= 'Init Value P' <= 10^4.\n",
      "    \n",
      "    'Init Value Pmat' : float\n",
      "        Default = 1.0\n",
      "    \n",
      "        The value of this option suggests P^0, the initial penalty\n",
      "        option for matrix inequalities.\n",
      "        It is similar to 'Init Value P' (and the same advice applies),\n",
      "        however, P^0 gets increased automatically if the matrix\n",
      "        constraints are more infeasible than the actual penalty option.\n",
      "    \n",
      "        Constraint: fourthroot(epsilon) <= 'Init Value Pmat' <= 10^4.\n",
      "    \n",
      "    'Inner Iteration Limit' : int\n",
      "        Default = 100\n",
      "    \n",
      "        The maximum number of the inner iterations (Newton steps) to be\n",
      "        performed by [Algorithm 2] in each outer iteration.\n",
      "        Setting the option too low might lead to `errno` = 23.\n",
      "        Values higher than 100 are unlikely to improve convergence.\n",
      "    \n",
      "        Constraint: 'Inner Iteration Limit' > 0.\n",
      "    \n",
      "    'Inner Stop Criteria' : str\n",
      "        Default = 'HEURISTIC'\n",
      "    \n",
      "        The precision alpha for the solution of the inner subproblem is\n",
      "        determined in [Algorithm 1] and under typical circumstances\n",
      "        [Algorithm 2] is expected to reach this precision within the\n",
      "        given 'Inner Iteration Limit'.\n",
      "        If any problems are detected and 'Inner Stop Criteria' =\n",
      "        'HEURISTIC', [Algorithm 2] is allowed to stop before reaching\n",
      "        the requested precision or the 'Inner Iteration Limit'.\n",
      "        This usually saves many unfruitful iterations and the solver may\n",
      "        recover in the following iterations.\n",
      "        If you suspect that the heuristic problem detection is not\n",
      "        suitable for your problem, setting 'Inner Stop Criteria' =\n",
      "        'STRICT' disallows such behaviour.\n",
      "    \n",
      "        Constraint: 'Inner Stop Criteria' = 'HEURISTIC' or 'STRICT'.\n",
      "    \n",
      "    'Inner Stop Tolerance' : float\n",
      "        Default = 10^-2\n",
      "    \n",
      "        This option sets the required precision alpha^0 for the first\n",
      "        inner problem solved by [Algorithm 2].\n",
      "        The precison of the solution of the inner problem does not need\n",
      "        to be very high in the first outer iterations and it is\n",
      "        automatically adjusted through the outer iterations to reach the\n",
      "        optimality limit epsilon_2 in the last one.\n",
      "    \n",
      "        Setting alpha^0 too restrictive (too low) causes an increase of\n",
      "        the number of inner iterations needed in the first outer\n",
      "        iterations and might lead to `errno` = 23.\n",
      "        In certain cases it might be helpful to use a more relaxed\n",
      "        (higher) alpha^0 and increase 'P Update Speed' which should\n",
      "        reduce the number of inner iterations needed at the beginning of\n",
      "        the computation in exchange for a possibly higher number of the\n",
      "        outer iterations.\n",
      "    \n",
      "        Constraint: epsilon < 'Inner Stop Tolerance' <= 10^3.\n",
      "    \n",
      "    'Linesearch Mode' : str\n",
      "        Default = 'AUTO'\n",
      "    \n",
      "        This controls the step size selection in [Algorithm 2].\n",
      "        If 'Linesearch Mode' = 'FULLSTEP' (the default for linear\n",
      "        problems), unit steps are taken where possible and the step\n",
      "        shortening takes place only to avoid undefined regions for the\n",
      "        matrix penalty function Phi_P() (see (6)).\n",
      "        This may be used for linear problems but it is not recommended\n",
      "        for any nonlinear ones.\n",
      "        If 'Linesearch Mode' = 'ARMIJO', Armijo backtracking linesearch\n",
      "        is used instead which is a fairly basic linesearch.\n",
      "        If 'Linesearch Mode' = 'GOLDSTEIN', a cubic safe guarded\n",
      "        linesearch based on Goldstein condition is employed, this is the\n",
      "        recommended (and default) choice for nonlinear problems.\n",
      "    \n",
      "        Constraint: 'Linesearch Mode' = 'AUTO', 'FULLSTEP', 'ARMIJO' or\n",
      "        'GOLDSTEIN'.\n",
      "    \n",
      "    'List' : str\n",
      "        Default = 'NO'\n",
      "    \n",
      "        This argument may be set to 'YES' if you wish to turn on\n",
      "        printing of each option specification as it is supplied.\n",
      "    \n",
      "        Constraint: 'List' = 'YES' or 'NO'\n",
      "    \n",
      "    'Monitor Frequency' : int\n",
      "        Default = 0\n",
      "    \n",
      "        If 'Monitor Frequency' > 0, the solver returns to you at the end\n",
      "        of every ith outer iteration.\n",
      "        During these intermediate exits, the current point `x` and\n",
      "        Lagrangian multipliers `u`, `ua` (if requested) are provided as\n",
      "        well as the statistics and error measures (`rinfo`, `stats`).\n",
      "        Argument `inform` helps to distinguish between intermediate and\n",
      "        final exits and also allows immediate termination.\n",
      "    \n",
      "        If 'Monitor Frequency' = 0, the solver stops only once on the\n",
      "        final point and no intermediate exits are made.\n",
      "    \n",
      "        Constraint: 'Monitor Frequency' >= 0.\n",
      "    \n",
      "    'Monitoring File' : int\n",
      "        Default = -1\n",
      "    \n",
      "        If i >= 0, the unit number for the secondary (monitoring)\n",
      "        output.\n",
      "        If set to -1, no secondary output is provided.\n",
      "        The following information is output to the unit:\n",
      "    \n",
      "        -   a listing of the options;\n",
      "    \n",
      "        -   problem statistics, the iteration log and the final status\n",
      "            as set by 'Monitoring Level'.\n",
      "    \n",
      "        Constraint: 'Monitoring File' >= -1.\n",
      "    \n",
      "    'Monitoring Level' : int\n",
      "        Default = 4\n",
      "    \n",
      "        This argument sets the amount of information detail that will be\n",
      "        printed by the solver to the secondary output.\n",
      "        The meaning of the levels is the same as with 'Print Level'.\n",
      "    \n",
      "        Constraint: 0 <= 'Monitoring Level' <= 5.\n",
      "    \n",
      "    'Outer Iteration Limit' : int\n",
      "        Default = 100\n",
      "    \n",
      "        The maximum number of the outer iterations to be performed by\n",
      "        [Algorithm 1].\n",
      "        If 'Outer Iteration Limit' = 0, no iteration is performed, only\n",
      "        quantities needed in the stopping criteria are computed and\n",
      "        returned in `rinfo`.\n",
      "        This might be useful in connection with 'Initial X' = 'USER' and\n",
      "        'Initial U' = 'USER' to check optimality of the given point.\n",
      "        However, note that the rules for possible modifications of the\n",
      "        starting point still apply, see `u` and `ua`.\n",
      "        Setting the option too low might lead to `errno` = 22.\n",
      "    \n",
      "        Constraint: 'Outer Iteration Limit' >= 0.\n",
      "    \n",
      "    'P Min' : float\n",
      "        Default = sqrt(epsilon)\n",
      "    \n",
      "        This controls p_min, the lowest possible penalty value p used\n",
      "        for (standard) inequalities.\n",
      "        In general, very small values of the penalty options cause\n",
      "        ill-conditioning which might lead to numerical difficulties.\n",
      "        On the other hand, very high p_min prevents the algorithm from\n",
      "        reaching the requested accuracy on the feasibility.\n",
      "        Under normal circumstances, the default value is recommended.\n",
      "    \n",
      "        Constraint: epsilon <= 'P Min' <= 10^-2.\n",
      "    \n",
      "    'Pmat Min' : float\n",
      "        Default = sqrt(epsilon)\n",
      "    \n",
      "        This is an equivalent of 'P Min' for the minimal matrix penalty\n",
      "        option P_min.\n",
      "        The same advice applies.\n",
      "    \n",
      "        Constraint: epsilon <= 'Pmat Min' <= 10^-2.\n",
      "    \n",
      "    'Preference' : str\n",
      "        Default = 'SPEED'\n",
      "    \n",
      "        This option affects how contributions from the matrix\n",
      "        constraints (6) to the system Hessian matrix are computed.\n",
      "        The default option of 'Preference' = 'SPEED' should be suitable\n",
      "        in most cases.\n",
      "        However, dealing with matrix constraints of a very high\n",
      "        dimension may cause noticable memory overhead and switching to\n",
      "        'Preference' = 'MEMORY' may be required.\n",
      "    \n",
      "        Constraint: 'Preference' = 'SPEED' or 'MEMORY'.\n",
      "    \n",
      "    'Presolve Block Detect' : str\n",
      "        Default = 'YES'\n",
      "    \n",
      "        If 'Presolve Block Detect' = 'YES', the matrix constraints are\n",
      "        checked during preprocessoring to determine if they can be split\n",
      "        into smaller independent ones, thus speeding up the solver.\n",
      "    \n",
      "        Constraint: 'Presolve Block Detect' = 'YES' or 'NO'.\n",
      "    \n",
      "    'Print File' : int\n",
      "        Default = advisory message unit number\n",
      "    \n",
      "        If i >= 0, the unit number for the primary output of the solver.\n",
      "        If 'Print File' = -1, the primary output is completely turned\n",
      "        off independently of other settings. The default value is the\n",
      "        advisory message unit number at the time of the options\n",
      "        initialization, e.g., at the initialization of the handle. The\n",
      "        following information is output to the unit:\n",
      "    \n",
      "        -   a listing of options if set by 'Print Options';\n",
      "    \n",
      "        -   problem statistics, the iteration log and the final status\n",
      "            from the solver as set by 'Print Level'.\n",
      "    \n",
      "        Constraint: 'Print File' >= -1.\n",
      "    \n",
      "    'Print Level' : int\n",
      "        Default = 2\n",
      "    \n",
      "        This argument defines how detailed information should be printed\n",
      "        by the solver to the primary output.\n",
      "    \n",
      "        [table omitted]\n",
      "    \n",
      "        Constraint: 0 <= 'Print Level' <= 5.\n",
      "    \n",
      "    'Print Options' : str\n",
      "        Default = 'YES'\n",
      "    \n",
      "        If 'Print Options' = 'YES', a listing of options will be printed\n",
      "        to the primary output.\n",
      "    \n",
      "        Constraint: 'Print Options' = 'YES' or 'NO'.\n",
      "    \n",
      "    'P Update Speed' : int\n",
      "        Default = 12\n",
      "    \n",
      "        This option affects the rate at which the penalty options p,P\n",
      "        are updated ([Algorithm 1], step (3)) and thus indirectly\n",
      "        influences the overall number of outer iterations.\n",
      "        Its value can be interpretted as the typical number of outer\n",
      "        iterations needed to get from the initial penalty values p^0,\n",
      "        P^0 half-way to the p_min and P_min.\n",
      "        Values smaller than 3 causes a very agressive penalty update\n",
      "        strategy which might lead to the increased number of inner\n",
      "        iterations and possibly to numerical difficulties.\n",
      "        On the other hand, values higher than 15 produce a relatively\n",
      "        conservative approach which leads to a higher number of the\n",
      "        outer iterations.\n",
      "    \n",
      "        If the solver encounters difficulties on your problem, a higher\n",
      "        value might help.\n",
      "        If your problem is working fine, setting a lower value might\n",
      "        increase the speed.\n",
      "    \n",
      "        Constraint: 1 <= 'P Update Speed' <= 100.\n",
      "    \n",
      "    'Stats Time' : str\n",
      "        Default = 'NO'\n",
      "    \n",
      "        This argument turns on timings of various parts of the algorithm\n",
      "        to give a better overview of where most of the time is spent.\n",
      "        This might be helpful for a choice of different solving\n",
      "        approaches.\n",
      "        It is possible to choose between CPU and wall clock time.\n",
      "        Choice 'YES' is equivalent to 'WALL CLOCK'.\n",
      "    \n",
      "        Constraint: 'Stats Time' = 'YES', 'NO', 'CPU' or 'WALL CLOCK'.\n",
      "    \n",
      "    'Stop Criteria' : str\n",
      "        Default = 'SOFT'\n",
      "    \n",
      "        If 'Stop Criteria' = 'SOFT', the solver is allowed to stop\n",
      "        prematurely with a suboptimal solution, `errno` = 50, if it\n",
      "        predicts that a better estimate of the solution cannot be\n",
      "        reached.\n",
      "        This is the recommended option.\n",
      "    \n",
      "        Constraint: 'Stop Criteria' = 'SOFT' or 'STRICT'.\n",
      "    \n",
      "    'Stop Tolerance 1' : float\n",
      "        Default = max(10^-6, sqrt(epsilon))\n",
      "    \n",
      "        This option defines epsilon_1 used as a tolerance for the\n",
      "        relative duality gap (0) and the relative precision (1), see\n",
      "        [Stopping Criteria].\n",
      "    \n",
      "        Constraint: 'Stop Tolerance 1' > epsilon.\n",
      "    \n",
      "    'Stop Tolerance 2' : float\n",
      "        Default = max(10^-7, sqrt(epsilon))\n",
      "    \n",
      "        This option sets the value epsilon_2 which is used for\n",
      "        optimality (2) and complementarity (4) tests from KKT conditions\n",
      "        or if 'DIMACS Measures' = 'Check' for all DIMACS error measures\n",
      "        instead.\n",
      "        See [Stopping Criteria].\n",
      "    \n",
      "        Constraint: 'Stop Tolerance 2' > epsilon.\n",
      "    \n",
      "    'Stop Tolerance Feasibility' : float\n",
      "        Default = max(10^-7, sqrt(epsilon))\n",
      "    \n",
      "        This argument places an acceptance limit on the feasibility of\n",
      "        the solution (3), epsilon_feas.\n",
      "        See [Stopping Criteria].\n",
      "    \n",
      "        Constraint: 'Stop Tolerance Feasibility' > epsilon.\n",
      "    \n",
      "    'Task' : str\n",
      "        Default = 'MINIMIZE'\n",
      "    \n",
      "        This argument specifies the required direction of the\n",
      "        optimization.\n",
      "        If 'Task' = 'FEASIBLE POINT', the objective function (if set) is\n",
      "        ignored and the algorithm stops as soon as a feasible point is\n",
      "        found with respect to the given tolerance.\n",
      "        If no objective function was set, 'Task' reverts to 'FEASIBLE\n",
      "        POINT' automatically.\n",
      "    \n",
      "        Constraint: 'Task' = 'MINIMIZE', 'MAXIMIZE' or 'FEASIBLE POINT'.\n",
      "    \n",
      "    'Transform Constraints' : str\n",
      "        Default = 'AUTO'\n",
      "    \n",
      "        This argument controls how equality constraints are treated by\n",
      "        the solver.\n",
      "        If 'Transform Constraints' = 'EQUALITIES', all equality\n",
      "        constraints h_k(x) = 0 from (4) are treated as two inequalities\n",
      "        h_k(x) <= 0 and h_k(x) >= 0, see [Solution of the inner\n",
      "        problem].\n",
      "        This is the default and the only option in this release for\n",
      "        equality constrained problems.\n",
      "    \n",
      "        Constraint: 'Transform Constraints' = 'AUTO', 'NO' or\n",
      "        'EQUALITIES'.\n",
      "    \n",
      "    'U Update Restriction' : float\n",
      "        Default = 0.5\n",
      "    \n",
      "        This defines the value mu_g giving the bounds on the updates of\n",
      "        Lagrangian multipliers for (standard) inequalities between the\n",
      "        outer iterations.\n",
      "        Values close to 1 limit the changes of the multipliers and serve\n",
      "        as a kind of smoothing, lower values allow more significant\n",
      "        changes.\n",
      "    \n",
      "        Based on numerical experience, big variation in the multipliers\n",
      "        may lead to a large number of iterations in the subsequent step\n",
      "        and might disturb the convergence due to ill-conditioning.\n",
      "    \n",
      "        It might be worth experimenting with the value on your\n",
      "        particular problem.\n",
      "        Mid range values are recommended over the more extremal ones.\n",
      "    \n",
      "        Constraint: epsilon < 'U Update Restriction' < 1.\n",
      "    \n",
      "    'Umat Update Restriction' : float\n",
      "        Default = 0.3\n",
      "    \n",
      "        This is an equivalent of 'U Update Restriction' for matrix\n",
      "        constraints, denoted as mu_A in [Overview].\n",
      "        The advice above applies equally.\n",
      "    \n",
      "        Constraint: epsilon < 'Umat Update Restriction' < 1.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    NagValueError\n",
      "        (`errno` 1)\n",
      "            `handle` has not been initialized.\n",
      "    \n",
      "        (`errno` 1)\n",
      "            `handle` does not belong to the NAG optimization modelling\n",
      "            suite, has not been initialized properly or is corrupted.\n",
      "    \n",
      "        (`errno` 1)\n",
      "            `handle` has not been initialized properly or is corrupted.\n",
      "    \n",
      "        (`errno` 2)\n",
      "            This solver does not support the model defined in the\n",
      "            handle.\n",
      "    \n",
      "        (`errno` 3)\n",
      "            The problem is already being solved.\n",
      "    \n",
      "        (`errno` 4)\n",
      "            On entry, nvar = *<value>*, expected value = *<value>*.\n",
      "    \n",
      "            Constraint: nvar must match the current number of variables\n",
      "            of the model in the `handle`.\n",
      "    \n",
      "        (`errno` 5)\n",
      "            On entry, nnzu = *<value>*.\n",
      "    \n",
      "            nnzu does not match the size of the Lagrangian multipliers\n",
      "            for (standard) constraints.\n",
      "    \n",
      "            nnzu = 0 or *<value>*.\n",
      "    \n",
      "        (`errno` 5)\n",
      "            On entry, nnzu = *<value>*.\n",
      "    \n",
      "            nnzu does not match the size of the Lagrangian multipliers\n",
      "            for (standard) constraints.\n",
      "    \n",
      "            nnzu = 0 when there are no (standard) constraints.\n",
      "    \n",
      "        (`errno` 5)\n",
      "            On entry, nnzua = *<value>*.\n",
      "    \n",
      "            nnzua does not match the size of the Lagrangian multipliers\n",
      "            for matrix constraints.\n",
      "    \n",
      "            nnzua = 0 or *<value>*.\n",
      "    \n",
      "        (`errno` 5)\n",
      "            On entry, nnzua = *<value>*.\n",
      "    \n",
      "            nnzua does not match the size of the Lagrangian multipliers\n",
      "            for matrix constraints.\n",
      "    \n",
      "            nnzua = 0 when there are no matrix constraints.\n",
      "    \n",
      "        (`errno` 5)\n",
      "            On entry, nnzuc = *<value>*.\n",
      "    \n",
      "            nnzuc does not match the size of the Lagrangian multipliers\n",
      "            for second-order cone constraints.\n",
      "    \n",
      "            nnzuc = 0 when there are no second-order cone constraints.\n",
      "    \n",
      "        (`errno` 21)\n",
      "            The current starting point is unusable.\n",
      "    \n",
      "        (`errno` 51)\n",
      "            The problem was found to be infeasible during preprocessing.\n",
      "    \n",
      "        (`errno` 52)\n",
      "            The problem was found unbounded during preprocessing.\n",
      "    \n",
      "        (`errno` 53)\n",
      "            The problem seems to be infeasible, the algorithm was\n",
      "            stopped.\n",
      "    \n",
      "        (`errno` 54)\n",
      "            The problem seems to be unbounded, the algorithm was\n",
      "            stopped.\n",
      "    \n",
      "    Warns\n",
      "    -----\n",
      "    NagAlgorithmicWarning\n",
      "        (`errno` 50)\n",
      "            The algorithm converged to a suboptimal solution.\n",
      "    \n",
      "            The full accuracy was not achieved. The solution should\n",
      "            still be usable.\n",
      "    \n",
      "    NagAlgorithmicMajorWarning\n",
      "        (`errno` 20)\n",
      "            User requested termination during a monitoring step.\n",
      "    \n",
      "        (`errno` 22)\n",
      "            Outer iteration limit has been reached.\n",
      "    \n",
      "            The requested accuracy is not achieved.\n",
      "    \n",
      "        (`errno` 23)\n",
      "            The inner subproblem could not be solved to the required\n",
      "            accuracy.\n",
      "    \n",
      "            Inner iteration limit has been reached.\n",
      "    \n",
      "        (`errno` 23)\n",
      "            The inner subproblem could not be solved to the required\n",
      "            accuracy.\n",
      "    \n",
      "            Limited progress in the inner subproblem triggered a stop\n",
      "            (heuristic inner stop criteria).\n",
      "    \n",
      "        (`errno` 23)\n",
      "            The inner subproblem could not be solved to the required\n",
      "            accuracy.\n",
      "    \n",
      "            Line search or another internal component failed.\n",
      "    \n",
      "        (`errno` 24)\n",
      "            Unable to make progress, the algorithm was stopped.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    ``handle_solve_pennon`` serves as a solver for compatible problems\n",
      "    stored as a handle.\n",
      "    The handle points to an internal data structure which defines the\n",
      "    problem and serves as a means of communication for functions in the\n",
      "    NAG optimization modelling suite.\n",
      "    First, the problem handle is initialized by calling ``handle_init``.\n",
      "    Then some of the functions ``handle_set_linobj``,\n",
      "    ``handle_set_quadobj``, ``handle_set_simplebounds``,\n",
      "    ``handle_set_linconstr``, ``handle_set_linmatineq`` or\n",
      "    ``handle_set_quadmatineq`` may be used to formulate the objective\n",
      "    function, (standard) constraints and matrix constraints of the\n",
      "    problem.\n",
      "    Once the problem is fully set, the handle may be passed to the\n",
      "    solver.\n",
      "    When the handle is no longer needed, ``handle_free`` should be\n",
      "    called to destroy it and deallocate the memory held within.\n",
      "    See [the E04 Introduction] for more details about the NAG\n",
      "    optimization modelling suite.\n",
      "    \n",
      "    Problems which can be defined this way are, for example, (generally\n",
      "    nonconvex) Quadratic Programming (QP)\n",
      "    \n",
      "        [table omitted]\n",
      "    \n",
      "    linear semidefinite programming problems (SDP)\n",
      "    \n",
      "        [table omitted]\n",
      "    \n",
      "    or semidefinite programming problems with bilinear matrix\n",
      "    inequalities (BMI-SDP)\n",
      "    \n",
      "        [table omitted]\n",
      "    \n",
      "    Here c, l_x and u_x are n-dimensional vectors, H is a symmetric n*n\n",
      "    matrix, l_B, u_B are m_B-dimensional vectors, B is a general m_B*n\n",
      "    rectangular matrix and A_i^k, Q_ij^k are symmetric matrices.\n",
      "    The expression S0 stands for a constraint on eigenvalues of a\n",
      "    symmetric matrix S, namely, all the eigenvalues should be\n",
      "    non-negative, i.e., the matrix should be positive semidefinite.\n",
      "    See relevant functions in the suite for more details on the problem\n",
      "    formulation.\n",
      "    \n",
      "    The solver is based on a generalized Augmented Lagrangian method\n",
      "    with a suitable choice of standard and matrix penalty functions.\n",
      "    For a detailed description of the algorithm see [Algorithmic\n",
      "    Details].\n",
      "    Under standard assumptions on the problem (Slater constraint\n",
      "    qualification, boundedness of the objective function on the feasible\n",
      "    set, see Stingl (2006) for details) the algorithm converges to a\n",
      "    local solution.\n",
      "    In case of convex problems such as linear SDP or convex QP, this is\n",
      "    the global solution.\n",
      "    The solver is suitable for both small dense and large-scale sparse\n",
      "    problems.\n",
      "    \n",
      "    The algorithm behaviour and solver strategy can be modified by\n",
      "    various options (see [Other Parameters]) which can be set by\n",
      "    ``handle_opt_set`` and ``handle_opt_set_file`` anytime between the\n",
      "    initialization of the handle by ``handle_init`` and a call to the\n",
      "    solver.\n",
      "    Once the solver has finished, options may be modified for the next\n",
      "    solve.\n",
      "    The solver may be called repeatedly with various starting points\n",
      "    and/or options.\n",
      "    \n",
      "    There are several options with a multiple choice where the default\n",
      "    choice is 'AUTO' (for example, 'Hessian Density').\n",
      "    This value means that the decision over the option is left to the\n",
      "    solver based on the structure of the problem.\n",
      "    Option getter ``handle_opt_get`` can be called to retrieve the\n",
      "    choice of these options as well as on any other options.\n",
      "    \n",
      "    Option 'Task' may be used to switch the problem to maximization or\n",
      "    to ignore the objective function and find only a feasible point.\n",
      "    \n",
      "    Option 'Monitor Frequency' may be used to turn on the monitor mode\n",
      "    of the solver.\n",
      "    The solver invoked in this mode pauses regularly even before the\n",
      "    optimal point is found to allow monitoring the progress from the\n",
      "    calling program.\n",
      "    All the important error measures and statistics are available in the\n",
      "    calling program which may terminate the solver early if desired (see\n",
      "    argument `inform`).\n",
      "    \n",
      "    Structure of the Lagrangian Multipliers\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    The algorithm works internally with estimates of both the decision\n",
      "    variables, denoted by x, and the Lagrangian multipliers (dual\n",
      "    variables) for standard and matrix constraints, denoted by u and U,\n",
      "    respectively.\n",
      "    You may provide initial estimates, request approximations during the\n",
      "    run (the monitor mode turned on) and obtain the final values.\n",
      "    The Lagrangian multipliers are split into two arrays, the\n",
      "    multipliers u for (standard) constraints are stored in array `u` and\n",
      "    multipliers U for matrix constraints in array `ua`.\n",
      "    Both arrays need to conform to the structure of the constraints.\n",
      "    \n",
      "    If the simple bounds were defined (``handle_set_simplebounds`` was\n",
      "    successfully called), the first 2n elements of `u` belong to the\n",
      "    corresponding Lagrangian multipliers, interleaving a multiplier for\n",
      "    the lower and for the upper bound for each x_i.\n",
      "    If any of the bounds were set to infinity, the corresponding\n",
      "    Lagrangian multipliers are set to 0 and may be ignored.\n",
      "    \n",
      "    Similarly, the following 2m_B elements of `u` belong to multipliers\n",
      "    for the linear constraints, if formulated by\n",
      "    ``handle_set_linconstr``.\n",
      "    The organization is the same, i.e., the multipliers for each\n",
      "    constraint for the lower and upper bounds are alternated and zeroes\n",
      "    are used for any missing (infinite bound) constraint.\n",
      "    \n",
      "    A Lagrangian multiplier for a matrix constraint (one block) of\n",
      "    dimension d*d is a dense symmetric matrix of the same dimension.\n",
      "    All multipliers U are stored next to each other in array `ua` in the\n",
      "    same order as the matrix constraints were defined by\n",
      "    ``handle_set_linmatineq`` and ``handle_set_quadmatineq``.\n",
      "    The lower triangle of each is stored in the packed column order (see\n",
      "    [the F07 Introduction]).\n",
      "    For example, if there are four matrix constraints of dimensions 7,\n",
      "    3, 1, 1, the dimension of array `ua` should be 36.\n",
      "    The first 28 elements (d_1*(d_1+1)/2) belong to the packed lower\n",
      "    triangle of U_1, followed by six elements of U_2 and one element for\n",
      "    each U_3 and U_4.\n",
      "    \n",
      "    Approximation of the Lagrangian Multipliers\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    By the nature of the algorithm, all inequality Lagrangian multiplier\n",
      "    u,U are always kept positive during the computational process.\n",
      "    This applies even to Lagrangian multipliers of inactive constraints\n",
      "    at the solution.\n",
      "    They will only be close to zero although they would normally be\n",
      "    equal to zero exactly.\n",
      "    This is one of the major differences between results from solvers\n",
      "    based on the active set method (such as ``qpconvex2_sparse_solve``)\n",
      "    and others, such as, ``handle_solve_pennon`` or interior point\n",
      "    methods.\n",
      "    As a consequence, the initial estimate of the multipliers (if\n",
      "    provided) might be adjusted by the solver to be sufficiently\n",
      "    positive, also the estimates returned during the intermediate exits\n",
      "    might only be a very crude approximation to their final values as\n",
      "    they do not satisfy all the Karush--Kuhn--Tucker (KKT) conditions.\n",
      "    \n",
      "    Another difference is that ``qpconvex2_sparse_solve`` merges\n",
      "    multipliers for both lower and upper inequality into one element\n",
      "    whose sign determines the inequality because there can be at most\n",
      "    one active constraint and multiplier for the inactive is exact zero.\n",
      "    Negative multipliers are associated with the upper bounds and\n",
      "    positive with the lower bounds.\n",
      "    On the other hand, ``handle_solve_pennon`` works with both\n",
      "    multipliers at the same time so they are returned in two elements,\n",
      "    one for the lower bound, the other for the upper bound (see\n",
      "    [Structure of the Lagrangian Multipliers]).\n",
      "    An equivalent result can be achieved by subtracting the upper bound\n",
      "    multiplier from the lower one.\n",
      "    This holds even when equalities are interpreted as two inequalities\n",
      "    (see option 'Transform Constraints').\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    Ben--Tal, A and Zibulevsky, M, 1997, `Penalty/barrier multiplier\n",
      "    methods for convex programming problems`, SIAM Journal on\n",
      "    Optimization (7), 347--366\n",
      "    \n",
      "    Fujisawa, K, Kojima, M, Nakata, K, 1997, `Exploiting sparsity in\n",
      "    primal-dual interior-point method for semidefinite programming`,\n",
      "    Math. Programming (79), 235--253\n",
      "    \n",
      "    Hogg, J D and Scott, J A, 2011, `HSL MA97: a bit-compatible\n",
      "    multifrontal code for sparse symmetric systems`, RAL Technical\n",
      "    Report. RAL-TR-2011-024\n",
      "    \n",
      "    Kovara, M and Stingl, M, 2003, `PENNON -- a code for convex\n",
      "    nonlinear and semidefinite programming`, Optimization Methods and\n",
      "    Software (18(3)), 317--333\n",
      "    \n",
      "    Kovara, M and Stingl, M, 2007, `On the solution of large-scale SDP\n",
      "    problems by the modified barrier method using iterative solvers`,\n",
      "    Math. Programming (Series B) (109(2--3)), 413--444\n",
      "    \n",
      "    Mittelmann, H D, 2003, `An independent benchmarking of SDP and SOCP\n",
      "    solvers`, Math. Programming (95), 407--430\n",
      "    \n",
      "    Stingl, M, 2006, `On the Solution of Nonlinear Semidefinite Programs\n",
      "    by Augmented Lagrangian Methods, PhD thesis`, Institute of Applied\n",
      "    Mathematics II, Friedrich--Alexander University of\n",
      "    Erlangen--Nuremberg\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    :meth:`naginterfaces.library.examples.opt.handle_solve_pennon_bmi_ex.main`\n",
      "    :meth:`naginterfaces.library.examples.opt.handle_solve_pennon_lmi_ex.main`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(opt.handle_solve_pennon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
